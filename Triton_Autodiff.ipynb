{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMJx7/7m25ZtGVv09QhYoSg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srush/triton-autodiff/blob/main/Triton_Autodiff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bNQCTEeKirdA"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -U triton==2.1.0 git+https://github.com/srush/tangent git+https://github.com/srush/triton-autodiff\n",
        "!export LC_ALL=\"en_US.UTF-8\"\n",
        "!export LD_LIBRARY_PATH=\"/usr/lib64-nvidia\"\n",
        "!export LIBRARY_PATH=\"/usr/local/cuda/lib64/stubs\"\n",
        "!ldconfig /usr/lib64-nvidia"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from triton_autodiff import *\n",
        "import torch\n",
        "import triton"
      ],
      "metadata": {
        "id": "YuvscqWxi1Cm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a triton mathematical function\n",
        "def fn1(x, y):\n",
        "    a = tl.exp(x)\n",
        "    b = tl.log(tl.expand_dims(y, 1))\n",
        "    c = a + b\n",
        "    return a * b + tl.dot(c, c)\n",
        "\n",
        "fn1_tt = triton.jit(fn1)\n",
        "\n",
        "# Signature of its backwards (generated function will print out)\n",
        "def fn1_back(x, y, dz):\n",
        "    pass\n",
        "fn1back_tt = grad(fn1, fn1_back, wrt=(0, 1))\n",
        "\n",
        "# Torch version for sanity check.\n",
        "def torch_check(x, y):\n",
        "    a = x.exp()\n",
        "    b = y[:, None].log()\n",
        "    c = a + b\n",
        "    return a * b + c @ c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsSIKfPCjGta",
        "outputId": "630f032c-509d-4d22-ce86-f2c3061fc4ca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def dfn1dxy(x, y, b_return=1.0):\n",
            "    a = tl.exp(x)\n",
            "    _b = tl.expand_dims(y, 1)\n",
            "    b = tl.log(_b)\n",
            "    c = a + b\n",
            "    tl_dot_c_c = tl.dot(c, c)\n",
            "    a_times_b = a * b\n",
            "    bx = zeroslike(x)\n",
            "    by = zeroslike(y)\n",
            "    b_b = zeroslike(_b)\n",
            "    bc = zeroslike(c)\n",
            "    bb = zeroslike(b)\n",
            "    ba = zeroslike(a)\n",
            "    btl_dot_c_c = zeroslike(tl_dot_c_c)\n",
            "    ba_times_b = zeroslike(a_times_b)\n",
            "\n",
            "    # Grad of: c = a + b\n",
            "    _ba_times_b = triton_unbroadcast(b_return, a_times_b.shape)\n",
            "    _btl_dot_c_c = triton_unbroadcast(b_return, tl_dot_c_c.shape)\n",
            "    ba_times_b = add_grad(ba_times_b, _ba_times_b)\n",
            "    btl_dot_c_c = add_grad(btl_dot_c_c, _btl_dot_c_c)\n",
            "    _ba2 = triton_unbroadcast(ba_times_b * b, a.shape)\n",
            "    _bb2 = triton_unbroadcast(ba_times_b * a, b.shape)\n",
            "    ba = add_grad(ba, _ba2)\n",
            "    bb = add_grad(bb, _bb2)\n",
            "    _bc = tl.trans(tl.dot(c, tl.trans(btl_dot_c_c)))\n",
            "    _bc2 = tl.dot(tl.trans(c), btl_dot_c_c)\n",
            "    bc = add_grad(bc, _bc)\n",
            "    bc = add_grad(bc, _bc2)\n",
            "    _ba = triton_unbroadcast(bc, a.shape)\n",
            "    _bb = triton_unbroadcast(bc, b.shape)\n",
            "    ba = add_grad(ba, _ba)\n",
            "    bb = add_grad(bb, _bb)\n",
            "\n",
            "    # Grad of: b = tl.log(tl.expand_dims(y, 1))\n",
            "    _b_b = bb / _b\n",
            "    b_b = add_grad(b_b, _b_b)\n",
            "    __b = _b\n",
            "    tl.static_assert(__b.shape[1] == 1)\n",
            "    _by = tl.view(b_b, y.shape)\n",
            "    by = add_grad(by, _by)\n",
            "\n",
            "    # Grad of: a = tl.exp(x)\n",
            "    _a = a\n",
            "    _bx = _a * ba\n",
            "    bx = add_grad(bx, _bx)\n",
            "    return bx, by\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Boilerplate load and forward\n",
        "@triton.jit\n",
        "def tr_forward(X, Y, Z):\n",
        "  r = tl.arange(0, 16)\n",
        "  r2 = tl.arange(0, 16)\n",
        "  x = tl.load(X + r)\n",
        "  y = tl.load(Y + r2)\n",
        "  z = fn1_tt(x, y)\n",
        "  tl.store(Z + 16 * r2[:, None] + r, z)\n",
        "\n",
        "# Boilerplate load and backward\n",
        "@triton.jit\n",
        "def tr_backward(X, Y, dX, dY, dZ):\n",
        "  r = tl.arange(0, 16)\n",
        "  r2 = tl.arange(0, 16)\n",
        "  x = tl.load(X + r)\n",
        "  y = tl.load(Y + r2)\n",
        "  dz = tl.load(dZ + 16 * r2[:, None] + r)\n",
        "  dx, dy = fn1back_tt(x, y, dz)\n",
        "  tl.store(dX + r, dx)\n",
        "  tl.store(dY + r2, dy)"
      ],
      "metadata": {
        "id": "ygzdUZE4jTbx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_run():\n",
        "    check(tr_forward, tr_backward, torch_check, x_shape=(16,), y_shape=(16,), z_shape=(16, 16))\n",
        "    print(\"check succeeded!\")\n",
        "test_run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBHQd_ppjY1d",
        "outputId": "3a30c986-585d-484b-f6d7-e05e496e0a2d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "check succeeded!\n"
          ]
        }
      ]
    }
  ]
}